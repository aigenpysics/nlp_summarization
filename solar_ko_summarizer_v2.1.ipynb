{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e02c8d1-e653-41a5-a94f-e44c176dbcc5",
   "metadata": {},
   "source": [
    "# 1. 개발 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa242e1-7689-4397-b410-d550e79246c3",
   "metadata": {},
   "source": [
    "### 1.1 필수 라이브러리 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d405d7a-f2c9-4416-bf88-880812a2b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Collecting peft\n",
      "  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/19/99/c5e0292a6d2a62e95c3dfe674ce9e8f8a9fe5d4835d3c9bb9b3e016f02ae/peft-0.11.1-py3-none-any.whl.metadata\n",
      "  Using cached peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.9.0\n",
      "    Uninstalling peft-0.9.0:\n",
      "      Successfully uninstalled peft-0.9.0\n",
      "Successfully installed peft-0.11.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U transformers==4.38.2\n",
    "!pip3 install -q -U datasets==2.18.0\n",
    "!pip3 install -q -U bitsandbytes==0.42.0\n",
    "!pip3 install -q -U peft==0.9.0\n",
    "!pip3 install --upgrade peft\n",
    "!pip3 install -q -U trl==0.7.11\n",
    "!pip3 install -q -U accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa79b6-4720-43d1-baae-41d834011c2c",
   "metadata": {},
   "source": [
    "### 1.2 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db58093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다.\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f30d7-bfdf-49c5-8c2c-701ad6f15a80",
   "metadata": {},
   "source": [
    "### 1.3 Huggingface 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa22976-7bdf-479d-8c5c-8ab890be537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd45d1cd6f4a4b238c5eea60a43a6325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98848a84-680e-4527-bdaf-f5cd7d635348",
   "metadata": {},
   "source": [
    "# 2. Dataset 생성 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa6125-b440-4458-b3dc-142aa7668110",
   "metadata": {},
   "source": [
    "### 2.1 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0098c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = '/data/ephemeral/home/data'\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'shuffled_merged_file.csv'))\n",
    "\n",
    "# validation data의 구조와 내용을 확인합니다.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a1bfb-b47c-448e-8957-86c00cc1df02",
   "metadata": {},
   "source": [
    "# 3. Solar 파인튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a886413-a19c-4966-9e07-ca8cdb23aa16",
   "metadata": {},
   "source": [
    "### 3.1 학습용 프롬프트 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26bd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(row):\n",
    "    topic = row['topic'] if 'topic' in row else ''\n",
    "    \n",
    "    prompt = f\"<s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:\\n\\ntopic: {topic}\\n\\ndialogue: {row['dialogue']}\\n<|im_end|>\\n<|im_start|>assistant\\n요약: {row['summary']}\\n<|im_end|> </s>\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cb6588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(row):#토픽 추출용\n",
    "    topic = row['topic'] if 'topic' in row else ''\n",
    "    \n",
    "    prompt = f\"<s> <|im_start|>system\\n다음 대화의 토픽을 찾으세요:\\n\\ndialogue: {row['dialogue']}\\n<|im_end|>\\n<|im_start|>assistant\\ntopic: {topic}\\n<|im_end|> </s>\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prompt'] = train_df.apply(generate_prompt, axis=1)\n",
    "val_df['prompt'] = val_df.apply(generate_prompt, axis=1)\n",
    "\n",
    "train_data = train_df['prompt']\n",
    "val_data = val_df['prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849b4c0-16f3-44f3-bb67-7022f226ec05",
   "metadata": {},
   "source": [
    "### 3.2 QLoRA 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3b30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5232dfa2224ac5af31c9d285b215c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch\n",
    "\n",
    "BASE_MODEL = \"beomi/Solar-Ko-Recovery-11B\"\n",
    "\n",
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=6,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map={\"\": \"cuda\"},\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# QLora 적용\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 토크나이저 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe9ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 시퀀스 길이: 283.83803863298664\n",
      "중앙값 시퀀스 길이: 263.0\n",
      "최대 시퀀스 길이: 1395\n",
      "최소 시퀀스 길이: 59\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 토큰화\n",
    "tokenized_data = tokenizer(train_df['prompt'].tolist())\n",
    "\n",
    "# 시퀀스 길이 계산\n",
    "seq_lengths = [len(seq) for seq in tokenized_data['input_ids']]\n",
    "\n",
    "# 시퀀스 길이 통계량 출력\n",
    "print(f\"평균 시퀀스 길이: {np.mean(seq_lengths)}\")\n",
    "print(f\"중앙값 시퀀스 길이: {np.median(seq_lengths)}\")\n",
    "print(f\"최대 시퀀스 길이: {np.max(seq_lengths)}\")\n",
    "print(f\"최소 시퀀스 길이: {np.min(seq_lengths)}\")\n",
    "\n",
    "# 시퀀스 길이 히스토그램 그리기\n",
    "plt.hist(seq_lengths, bins=50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sequence Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db62d4-05ef-41ad-ad7b-a9c734c1b67d",
   "metadata": {},
   "source": [
    "### 3.3 Trainer 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ef6fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    }
   ],
   "source": [
    "wandb_key = ''\n",
    "wandb.login(key=wandb_key, relogin=True)\n",
    "\n",
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_ENTITY\"] = 'upstage-ai-comp'\n",
    "\n",
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"] = ''\n",
    "\n",
    "# save your trained model checkpoint to wandb\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n",
    "\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"] = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2565307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3f670a7670422aa1237207fa10a788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03807bea05fd422cb4d5a276bb5d8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_metric\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "# 훈련 데이터 로드\n",
    "train_data = Dataset.from_dict({\"prompt\": train_df['prompt']})\n",
    "\n",
    "# 검증 데이터 로드\n",
    "val_data = Dataset.from_dict({\"prompt\": val_df['prompt']})\n",
    "\n",
    "def formattingfunc(example):\n",
    "    return example['prompt']\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        eval_accumulation_steps=4,\n",
    "        dataloader_num_workers=0,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        warmup_steps=0.05,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        max_grad_norm=0.3,\n",
    "        weight_decay=0.001,\n",
    "        report_to=\"none\",#속도가 느려져서 완드비 껐습니다 필요에 따라 켜주세요\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formattingfunc,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = SFTTrainer(\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        eval_accumulation_steps=4,\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        warmup_steps=0.05,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        max_grad_norm=0.3,\n",
    "        weight_decay=0.001,\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formattingfunc,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fd7e65-334d-4052-9ab5-3c8e71bf09a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='13626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5000/13626 6:23:32 < 11:01:56, 0.22 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.601700</td>\n",
       "      <td>1.452284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.461700</td>\n",
       "      <td>1.428586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.460700</td>\n",
       "      <td>1.420713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.480800</td>\n",
       "      <td>1.406855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.467900</td>\n",
       "      <td>1.409438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.442500</td>\n",
       "      <td>1.392212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.426600</td>\n",
       "      <td>1.399883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.411100</td>\n",
       "      <td>1.396948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.447000</td>\n",
       "      <td>1.386747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.406600</td>\n",
       "      <td>1.384652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.422000</td>\n",
       "      <td>1.385471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.384300</td>\n",
       "      <td>1.383862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.388700</td>\n",
       "      <td>1.378729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.418100</td>\n",
       "      <td>1.369852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.377200</td>\n",
       "      <td>1.366943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.369900</td>\n",
       "      <td>1.370911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.341900</td>\n",
       "      <td>1.367008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.361800</td>\n",
       "      <td>1.362852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.344300</td>\n",
       "      <td>1.360908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.345900</td>\n",
       "      <td>1.359409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.373100</td>\n",
       "      <td>1.356591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.360700</td>\n",
       "      <td>1.359180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.323600</td>\n",
       "      <td>1.356313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.306700</td>\n",
       "      <td>1.354733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.317200</td>\n",
       "      <td>1.351134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.309900</td>\n",
       "      <td>1.356291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.329100</td>\n",
       "      <td>1.347848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.320500</td>\n",
       "      <td>1.350324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>1.350408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.279500</td>\n",
       "      <td>1.349401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.274000</td>\n",
       "      <td>1.347274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.285400</td>\n",
       "      <td>1.346634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.317200</td>\n",
       "      <td>1.343403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.287700</td>\n",
       "      <td>1.337055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.262300</td>\n",
       "      <td>1.336523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.274700</td>\n",
       "      <td>1.336840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.335515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.264500</td>\n",
       "      <td>1.339826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.285400</td>\n",
       "      <td>1.339056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.275900</td>\n",
       "      <td>1.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.249400</td>\n",
       "      <td>1.337123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.243400</td>\n",
       "      <td>1.333345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.223000</td>\n",
       "      <td>1.334767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.226800</td>\n",
       "      <td>1.333818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.238900</td>\n",
       "      <td>1.331428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.102800</td>\n",
       "      <td>1.348934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.976800</td>\n",
       "      <td>1.348101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.020300</td>\n",
       "      <td>1.349560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.004800</td>\n",
       "      <td>1.349434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.018400</td>\n",
       "      <td>1.352027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory outputs/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory outputs/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "ADAPTER_MODEL = \"lora_adapter_last\"\n",
    "\n",
    "#wandb.finish()\n",
    "\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2c237-71f4-47c2-bad4-181dadb6cc98",
   "metadata": {},
   "source": [
    "# 4. Solar 한국어 요약 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587dfc7-cf7c-4072-a8f7-6ceb1e90a532",
   "metadata": {},
   "source": [
    "#### 주의: 마찬가지로 Colab GPU 메모리 한계로 학습 시 사용했던 메모리를 비워 줘야 파인튜닝을 진행 할 수 있습니다. <br> notebook 런타임 세션을 재시작 한 후 1번과 2번의 2.1 항목까지 다시 실행하여 로드 한 후 아래 과정을 진행합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78399236-63b5-41af-9cee-a7233e23a9db",
   "metadata": {},
   "source": [
    "### 4.1 Fine-tuned 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48615825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4307cf798b48308857e11484e6f76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"beomi/Solar-Ko-Recovery-11B\"\n",
    "ADAPTER_MODEL = \"lora_adapter_last\"\n",
    "\n",
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map={\"\": \"cuda\"},\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map={\"\": \"cuda\"}, torch_dtype=torch.float16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34718c-ce52-4d68-ac8c-c18b6483b15b",
   "metadata": {},
   "source": [
    "### 4.2 Fine-tuned 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0061c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>#Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...</td>\n",
       "      <td>비디오 게임</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\n#Person2...</td>\n",
       "      <td>컨트리 음악</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>#Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...</td>\n",
       "      <td>세탁기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>#Person1#: 매튜? 안녕!\\n#Person2#: 스티브! 오랜만이네! 얼마나...</td>\n",
       "      <td>집 찾기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>#Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ...</td>\n",
       "      <td>승진</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                           dialogue   topic\n",
       "494  test_495  #Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...  비디오 게임\n",
       "495  test_496  #Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\n#Person2...  컨트리 음악\n",
       "496  test_497  #Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...     세탁기\n",
       "497  test_498  #Person1#: 매튜? 안녕!\\n#Person2#: 스티브! 오랜만이네! 얼마나...    집 찾기\n",
       "498  test_499  #Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ...      승진"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 test data를 불러옵니다.\n",
    "data_path = '/data/ephemeral/home/data'\n",
    "\n",
    "# test data의 구조와 내용을 확인합니다.\n",
    "test_df = pd.read_csv(os.path.join(data_path,'test_with_topic.csv'))\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0805c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_prompt(row):\n",
    "    prompt = f\"<s><|im_start|>system\\n다음 대화를 요약해주세요:\\n\\ndialogue: {row['dialogue']}\\n<|im_end|>\\n<|im_start|>assistant\\n요약:\" #<|im_end|></s>\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9794f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_prompt(row):#토픽 있을때\n",
    "    topic = row['topic'] if 'topic' in row else ''\n",
    "    prompt = f\"<s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:\\n\\ntopic: {topic}\\n\\ndialogue: {row['dialogue']}\\n<|im_end|>\\n<|im_start|>assistant\\n요약:\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11bc4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_prompt(row):#토픽 추출용\n",
    "    prompt = f\"<s><|im_start|>system\\n다음 대화의 토픽을 찾으세요:\\n\\ndialogue: {row['dialogue']}\\n<|im_end|>\\n<|im_start|>assistant\\ntopic:\" #<|im_end|></s>\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e471584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>topic</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \\n#Person2#: 네, ...</td>\n",
       "      <td>내부 메모</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\\n#Person2#: 또...</td>\n",
       "      <td>교통 체증</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \\n#Per...</td>\n",
       "      <td>이혼</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\\n#Person...</td>\n",
       "      <td>생일 파티</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: 이 올림픽 공원이 정말 크네요!\\n#Person2#: 네. 지금...</td>\n",
       "      <td>올림픽 공원</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>#Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...</td>\n",
       "      <td>비디오 게임</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\n#Person2...</td>\n",
       "      <td>컨트리 음악</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>#Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...</td>\n",
       "      <td>세탁기</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>#Person1#: 매튜? 안녕!\\n#Person2#: 스티브! 오랜만이네! 얼마나...</td>\n",
       "      <td>집 찾기</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>#Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ...</td>\n",
       "      <td>승진</td>\n",
       "      <td>&lt;s&gt; &lt;|im_start|&gt;system\\n주제를 참고해 다음 대화를 요약해주세요:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                           dialogue   topic  \\\n",
       "0      test_0  #Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \\n#Person2#: 네, ...   내부 메모   \n",
       "1      test_1  #Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\\n#Person2#: 또...   교통 체증   \n",
       "2      test_2  #Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \\n#Per...      이혼   \n",
       "3      test_3  #Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\\n#Person...   생일 파티   \n",
       "4      test_4  #Person1#: 이 올림픽 공원이 정말 크네요!\\n#Person2#: 네. 지금...  올림픽 공원   \n",
       "..        ...                                                ...     ...   \n",
       "494  test_495  #Person1#: 헤이, 찰리, 학교 끝나고 우리 집에 와서 나랑 비디오 게임 할...  비디오 게임   \n",
       "495  test_496  #Person1#: 어떻게 컨트리 음악에 관심을 가지게 되었나요?\\n#Person2...  컨트리 음악   \n",
       "496  test_497  #Person1#: 실례합니다, 앨리스. 이곳을 사용해본 적이 없는데, 기계를 어떻...     세탁기   \n",
       "497  test_498  #Person1#: 매튜? 안녕!\\n#Person2#: 스티브! 오랜만이네! 얼마나...    집 찾기   \n",
       "498  test_499  #Person1#: 헤이, 벳시, 좋은 소식 들었어?\\n#Person2#: 아니, ...      승진   \n",
       "\n",
       "                                                prompt  \n",
       "0    <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "1    <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "2    <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "3    <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "4    <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "..                                                 ...  \n",
       "494  <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "495  <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "496  <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "497  <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "498  <s> <|im_start|>system\\n주제를 참고해 다음 대화를 요약해주세요:...  \n",
       "\n",
       "[499 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['prompt'] = test_df.apply(generate_test_prompt, axis=1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a3c314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/499 [00:09<1:18:55,  9.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 더슨 씨에게 모든 직원에게 내부 메모를 전달하라고 요청합니다. 메모는 즉시 메시지를 사용하는 것을 금지하고, 두 번째 위반 시 해고될 수 있다고 경고합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/499 [01:45<1:17:40,  9.55s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#에게 허베이에서 심각한 모래폭풍이 일어나고 있다고 말한다. #Person2#는 모래폭풍이 이 지역에 사는 사람들에게 어떤 영향을 미치는지 묻는다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/499 [03:20<1:15:51,  9.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프랭크는 주디에게 우체국에서 새로운 일자리를 얻었다고 말한다. 그는 힘든 일과 짧은 점심시간에도 불구하고 이 일자리를 선택한 이유는 우체국이 직원들에게 훌륭한 건강보험 혜택을 제공하기 때문이다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31/499 [04:55<1:13:44,  9.45s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴리 씨는 끔찍한 일을 잊기 위해 탄산 음료 한 병을 사려고 합니다. #Person1#은 상사가 가게에 있기 때문에 폴리 씨에게 직접 가게에 가라고 요청합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/499 [06:30<1:12:30,  9.50s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 펜던트가 부러져서 #Person2#에게 교체해달라고 요청했습니다. #Person2#는 동의했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/499 [08:06<1:10:23,  9.43s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 중요한 일 때문에 프렌드십 호텔로 서둘러야 합니다. #Person2#는 #Person1#을 목적지까지 빠르게 데려다 줍니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/499 [09:41<1:09:24,  9.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잭은 #Person1#에게 정치학 수업이 좋았지만, 비즈니스 커뮤니케이션 수업이 가장 좋다고 말했다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 71/499 [11:16<1:07:34,  9.47s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#에게 공장이 75,000 제곱미터의 면적을 가지고 있으며, 500명의 직원이 있으며, 원자재부터 완제품까지 모든 것을 다루고 있다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 81/499 [12:52<1:06:50,  9.59s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#에게 차량 사고에 대해 알리고, #Person2#는 구급차와 경찰을 불러줄 것입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/499 [14:26<1:04:00,  9.41s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 소풍 갈 때 과일을 가져가려고 한다. #Person2#는 #Person1#에게 바나나와 포도를 가져가라고 제안한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/499 [16:01<1:03:27,  9.57s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#과 #Person2#는 트럼프에 대해 다른 의견을 가지고 있다. #Person1#은 그가 다시 대통령이 되는 것을 상상조차 할 수 없지만, #Person2#는 그가 다시 선출되면 행복할 것이다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 111/499 [17:36<1:01:34,  9.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 새해 결심으로 다이어트를 시작하기로 결정했지만, 캐롤은 #Person1#이 이 약속을 지킬 수 있을지 의심한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/499 [19:12<1:00:07,  9.54s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#에게 강아지들에게 밥을 주고 목욕을 시켜달라고 요청했습니다. #Person1#은 #Person2#에게 동물병원에 가는 것을 상기시켰습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 131/499 [20:47<58:31,  9.54s/ examples]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 과학 박물관으로 가는 길을 묻기 위해 #Person2#에게 도움을 청하고, #Person2#는 #Person1#에게 어떻게 해야 하는지 알려준다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141/499 [22:23<57:05,  9.57s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#에게 화를 냈지만, #Person2#는 큰 산불을 끄러 가야 했다. #Person1#은 #Person2#에게 임신했다고 말한다. #Person2#는 기뻐한다. #Person3#는 #Person1#의 검사 결과를 알려준다. #Person2#는 아기가 자신의 아기가 아니라고 생각한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/499 [23:58<55:23,  9.55s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 컴퓨터에 바이러스가 있다고 생각하지만, #Person1#는 #Person2#의 이메일이 너무 크다고 말한다. #Person1#는 #Person2#에게 압축해서 보내라고 조언한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/499 [25:32<52:36,  9.34s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#과 #Person2#는 배와 보트가 예전처럼 교통수단으로 중요하지 않다는 것에 동의합니다. #Person1#은 사람들이 배로 여행하고 싶어하지 않는 이유는 사람들의 생활 속도가 점점 빨라지고 있기 때문이라고 생각합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 171/499 [27:07<52:06,  9.53s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 센트럴 백화점으로 가는 길을 묻고, #Person2#는 #Person1#에게 길을 알려줍니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 181/499 [28:42<50:25,  9.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앤은 삼-오에게 전화를 걸어 다시 만나고 싶지 않다고 말한다. 삼-오는 놀라며 그녀에게 두 번째 기회를 달라고 요청하지만 앤은 거절한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/499 [30:17<48:47,  9.50s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월터와 스털링은 우드 교수님이 뛰어난 과학자라고 생각하지만, 정신이 좀 딴 데 팔린 것 같다고 생각한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/499 [31:53<47:29,  9.56s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 배가 고프다. #Person2#는 몇 가지 요리를 추천하지만 #Person1#은 매운 음식을 좋아하지 않는다. #Person2#는 베이징 요리를 추천하고 #Person1#에게 가장 좋은 식당인 전취덕을 알려준다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 211/499 [33:28<45:41,  9.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 빌에게 젖은 페인트에 손대지 말라고 경고한다. 빌은 동의하지만, 존 샘슨처럼 무심코 행동하지 않을 것이라고 말한다. #Person1#은 작업자들이 공지를 붙이지 않는 것에 대해 불평한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 221/499 [35:04<44:09,  9.53s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 대출 신청에 대한 정보를 얻고 싶어합니다. #Person1#는 #Person2#에게 대출의 일반적인 조건을 알려줍니다. #Person2#는 신용 점수가 매우 낮아서 대출을 신청하지 않을 것입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 231/499 [36:40<42:31,  9.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#에게 호주에 가고 싶다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 241/499 [38:16<41:31,  9.66s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에밀리는 수잔에게 급여에 대한 몇 가지 질문을 한다. 수잔은 에밀리에게 FICA와 SUI Y 세금이 무엇인지, 그리고 메디케어와 그녀의 건강 보험 계획에 대한 공제가 왜 있는지 설명한다. 에밀리는 수잔에게 도움을 주어서 감사하다고 말한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/499 [39:51<39:17,  9.50s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#의 도움으로 티켓을 찾습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 261/499 [41:26<37:38,  9.49s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 머피 뮤직과 U-튠즈가 합병한다는 것을 #Person2#에게 알려줍니다. #Person2#는 처음에는 믿지 않았지만, #Person1#은 금융 페이지에서 읽었다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 271/499 [43:02<36:20,  9.56s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "브라운 씨는 #Person2#에게 월급을 제안하고, #Person2#는 동의한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 281/499 [44:37<34:42,  9.55s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#과 #Person2#는 음식을 주문하기 위해 줄을 서고 있습니다. #Person1#은 크림 케이크를 원하고, #Person2#는 그것을 좋아하지 않습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 291/499 [46:13<33:08,  9.56s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#의 도움으로 알루미늄 팬과 나무 핸들을 가진 알루미늄 팬을 구입했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/499 [47:48<31:16,  9.48s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 켄이 돌아오면 가능한 한 빨리 비상 회의를 소집하도록 #Person2#에게 요청했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 311/499 [49:23<29:29,  9.41s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다니엘은 과학이 가장 좋다고 말하지만, #Person2#는 그가 체육을 좋아할 것이라고 생각했습니다. 다니엘은 #Person2#에게 과학에 관심이 있는 이유를 설명합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 321/499 [50:58<28:14,  9.52s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 목이 말라 죽을 지경입니다. #Person2#는 #Person1#에게 물을 마시라고 제안합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 331/499 [52:33<26:31,  9.47s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#의 도움으로 중앙에 있는 테이블을 선택하고, #Person2#의 친구를 기다리기 위해 20분 후에 음식을 준비하도록 요청합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 341/499 [54:08<24:55,  9.47s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 잭에게 #Person1#의 새로운 강아지를 보여주고, 잭은 그것이 귀엽다고 생각한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 351/499 [55:43<23:24,  9.49s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 #Person2#에게 CA216 비행기가 지연된 이유를 묻습니다. #Person2#는 폭우 때문이라고 말합니다. #Person1#은 더 자세한 정보를 요청하지만, #Person2#는 현재로서는 알 수 없다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 361/499 [57:18<21:51,  9.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#과 #Person2#는 볼티모어에서 야구 경기를 보고 있습니다. #Person2#는 #Person1#에게 현재 점수와 야구 경기장을 칭찬합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 371/499 [58:53<20:08,  9.44s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#에게 영어 노래가 있지만, 그것들을 찾는 데 몇 분 더 걸릴 수 있다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 381/499 [1:00:29<18:56,  9.63s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#에게 9년 동안 우표 수집에 관심을 가지고 있으며, 첫 우표에는 퀸 빅토리아의 사진이 그려져 있다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 391/499 [1:02:04<17:05,  9.49s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "티나는 #Person1#에게 8년 동안 피아노를 배웠으며, 그녀의 선생님은 영국 출신의 훌륭한 선생님이라고 말한다. #Person1#는 그 선생님을 만나고 싶어한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/499 [1:03:39<15:23,  9.42s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 집주인과 수리 비용에 대해 불평하고 있습니다. #Person2#는 집주인이 수리를 하지 않는 것이 아니라 너무 오래 걸리는 것이라고 말합니다. #Person2#는 #Person1#에게 집주인이 수리를 하지 않는다고 말합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 411/499 [1:05:14<13:59,  9.54s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메리는 앤과 큰 싸움을 했고, #Person1#은 그녀에게 앤이 남자친구를 따라가야 하는 상황을 이해하라고 제안한다. 메리는 앤에게 사과할 것이다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 421/499 [1:06:50<12:27,  9.58s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 오래된 포드 핀토를 팔고 새 차를 사고 싶어합니다. #Person2#는 포드 포커스를 추천하고 #Person1#에게 그 장점을 소개합니다. #Person1#은 그 차를 좋아하고 시승해봅니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 431/499 [1:08:25<10:46,  9.51s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 탕 씨를 인터뷰하고 탕 씨는 #Person1#에게 자신의 자격에 대해 설명합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 441/499 [1:10:01<09:16,  9.59s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 결혼할 준비가 되지 않았다고 생각하고, 결혼을 망치고 싶어한다. #Person2#는 #Person1#에게 에이미를 놓치지 말라고 설득하고, #Person1#은 마음을 바꾸고 결혼하기로 결정한다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/499 [1:11:36<07:37,  9.53s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 #Person1#에게 피크 트램으로 가는 방법을 알려줍니다. #Person1#는 #Person2#에게 연필을 달라고 요청하여 그 방법을 적어둘 수 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 461/499 [1:13:12<06:04,  9.60s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 목욕을 하려고 하는데 스위치를 어떻게 사용하는지 모르기 때문에 #Person2#에게 도움을 청하고 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 471/499 [1:14:47<04:27,  9.56s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person2#는 새로운 계좌를 개설하고 싶어합니다. #Person1#는 #Person2#에게 신청서를 작성하고 여권을 가져오라고 요청합니다. #Person1#는 #Person2#에게 당좌 계좌와 저축 계좌를 모두 개설할 수 있으며, 초과 인출을 할 수 있는 최대 금액은 $1000이며, 초과 인출에 대한 벌금은 1%라고 말합니다. #Person2#는 서류가 모두 괜찮다고 생각합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 481/499 [1:16:23<02:52,  9.58s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#와 #Person2#는 방을 정리하고 있다. 그들은 동전을 던져서 아래쪽 침대를 #Person2#에게, 창가 옆의 책상을 #Person1#에게, 그리고 스테레오를 #Person1#에게 준다. #Person1#는 먼저 먹을 것을 가지러 가고, #Person2#는 먼저 짐을 풀어놓을 것이다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 491/499 [1:17:59<01:16,  9.59s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#은 제임스가 기차를 타기 위해 짐을 싸는 것을 돕고 있습니다. 제임스는 데이비드에게 빌려준 재킷을 기다리고 있고, #Person1#은 제임스에게 쿠키를 가져가라고 요청합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [1:19:15<00:00,  9.53s/ examples]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import TextStreamer\n",
    "import re\n",
    "\n",
    "def generate_summary(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    #return output_text\n",
    "\n",
    "    # 요약문 추출\n",
    "    summaries = []\n",
    "    for line in output_text.split(\"\\n\"):\n",
    "        if line.startswith(\"요약:\"):\n",
    "            summary = line[4:].strip()\n",
    "            summaries.append(summary)\n",
    "\n",
    "    # 첫 번째 요약문 반환\n",
    "    if summaries:\n",
    "        return summaries[0]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "test_df['summary'] = ''  # 'summary' 열 초기화\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), unit=' examples', leave=True):\n",
    "    prompt = row['prompt']\n",
    "    summary = generate_summary(prompt)\n",
    "    if index%10 == 0 : \n",
    "        print(summary)\n",
    "    test_df.at[index, 'summary'] = summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acaed52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('/data/ephemeral/home/data/sample_submission.csv', index_col=0)\n",
    "sample_sub['summary'] = test_df['summary']\n",
    "sample_sub.to_csv('./output_solar_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03f79afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 20 07:57:36 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:4B:00.0 Off |                  N/A |\n",
      "| 75%   65C    P2             343W / 350W |  23972MiB / 24576MiB |     87%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
